{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from scipy.stats import randint\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import RepeatedKFold \n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>fsc_mean</th>\n",
       "      <th>fsc_var</th>\n",
       "      <th>fsb_mean</th>\n",
       "      <th>fsb_var</th>\n",
       "      <th>chroma_mean</th>\n",
       "      <th>chroma_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_mean21</th>\n",
       "      <th>mfcc_mean22</th>\n",
       "      <th>mfcc_mean23</th>\n",
       "      <th>mfcc_mean24</th>\n",
       "      <th>mfcc_mean25</th>\n",
       "      <th>mfcc_mean26</th>\n",
       "      <th>mfcc_mean27</th>\n",
       "      <th>mfcc_mean28</th>\n",
       "      <th>mfcc_mean29</th>\n",
       "      <th>mfcc_mean30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>blues</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>0.362313</td>\n",
       "      <td>0.106962</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.534350</td>\n",
       "      <td>-1.141433</td>\n",
       "      <td>-4.283032</td>\n",
       "      <td>-4.226195</td>\n",
       "      <td>0.915617</td>\n",
       "      <td>0.912687</td>\n",
       "      <td>-5.761347</td>\n",
       "      <td>-3.932743</td>\n",
       "      <td>1.510824</td>\n",
       "      <td>2.698882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>blues</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>0.460052</td>\n",
       "      <td>0.142584</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.095796</td>\n",
       "      <td>-1.239113</td>\n",
       "      <td>-2.849731</td>\n",
       "      <td>-4.350280</td>\n",
       "      <td>3.272610</td>\n",
       "      <td>1.219840</td>\n",
       "      <td>-0.011623</td>\n",
       "      <td>-0.068070</td>\n",
       "      <td>3.977461</td>\n",
       "      <td>-0.455880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>blues</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>0.273189</td>\n",
       "      <td>0.044912</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.050981</td>\n",
       "      <td>-0.572249</td>\n",
       "      <td>-2.018496</td>\n",
       "      <td>-5.387675</td>\n",
       "      <td>-5.137322</td>\n",
       "      <td>-7.807413</td>\n",
       "      <td>-1.173293</td>\n",
       "      <td>-0.211240</td>\n",
       "      <td>1.391639</td>\n",
       "      <td>-3.002489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>blues</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>0.341006</td>\n",
       "      <td>0.062565</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.497070</td>\n",
       "      <td>-0.052236</td>\n",
       "      <td>-1.860378</td>\n",
       "      <td>-4.708420</td>\n",
       "      <td>-3.922396</td>\n",
       "      <td>-6.646778</td>\n",
       "      <td>-2.896451</td>\n",
       "      <td>-3.225220</td>\n",
       "      <td>-0.269411</td>\n",
       "      <td>-3.817974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>blues</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>0.192628</td>\n",
       "      <td>0.038132</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.864221</td>\n",
       "      <td>-0.721730</td>\n",
       "      <td>0.956659</td>\n",
       "      <td>-1.220395</td>\n",
       "      <td>4.582734</td>\n",
       "      <td>0.304413</td>\n",
       "      <td>-1.278633</td>\n",
       "      <td>-4.487785</td>\n",
       "      <td>-0.413578</td>\n",
       "      <td>0.281198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>rock.00095.wav</td>\n",
       "      <td>rock</td>\n",
       "      <td>2008.149458</td>\n",
       "      <td>282174.689224</td>\n",
       "      <td>2106.541053</td>\n",
       "      <td>88609.749506</td>\n",
       "      <td>0.181401</td>\n",
       "      <td>0.029210</td>\n",
       "      <td>0.079486</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.957475</td>\n",
       "      <td>-4.317051</td>\n",
       "      <td>-6.250848</td>\n",
       "      <td>0.721220</td>\n",
       "      <td>-4.338227</td>\n",
       "      <td>-6.950669</td>\n",
       "      <td>-5.784535</td>\n",
       "      <td>-8.634680</td>\n",
       "      <td>-5.663607</td>\n",
       "      <td>-2.196216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>rock.00096.wav</td>\n",
       "      <td>rock</td>\n",
       "      <td>2006.843354</td>\n",
       "      <td>182114.709510</td>\n",
       "      <td>2068.942009</td>\n",
       "      <td>82426.016726</td>\n",
       "      <td>0.273710</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.076458</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.678435</td>\n",
       "      <td>-3.787277</td>\n",
       "      <td>-6.231989</td>\n",
       "      <td>1.612385</td>\n",
       "      <td>-1.756582</td>\n",
       "      <td>-2.808209</td>\n",
       "      <td>-2.458402</td>\n",
       "      <td>-10.967601</td>\n",
       "      <td>-6.270818</td>\n",
       "      <td>-7.800555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>rock.00097.wav</td>\n",
       "      <td>rock</td>\n",
       "      <td>2077.526598</td>\n",
       "      <td>231657.968040</td>\n",
       "      <td>1927.293153</td>\n",
       "      <td>74717.124394</td>\n",
       "      <td>0.385682</td>\n",
       "      <td>0.074642</td>\n",
       "      <td>0.081651</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.942582</td>\n",
       "      <td>-2.529781</td>\n",
       "      <td>-2.786954</td>\n",
       "      <td>-0.166313</td>\n",
       "      <td>-5.404921</td>\n",
       "      <td>-6.479573</td>\n",
       "      <td>-3.047574</td>\n",
       "      <td>-5.260037</td>\n",
       "      <td>0.551845</td>\n",
       "      <td>-3.021486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>rock.00098.wav</td>\n",
       "      <td>rock</td>\n",
       "      <td>1398.699344</td>\n",
       "      <td>240318.731073</td>\n",
       "      <td>1818.450280</td>\n",
       "      <td>109090.207161</td>\n",
       "      <td>0.469807</td>\n",
       "      <td>0.122644</td>\n",
       "      <td>0.083860</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.717012</td>\n",
       "      <td>-6.297633</td>\n",
       "      <td>-6.245030</td>\n",
       "      <td>-3.727469</td>\n",
       "      <td>-1.884362</td>\n",
       "      <td>-5.773752</td>\n",
       "      <td>-2.096236</td>\n",
       "      <td>-2.320376</td>\n",
       "      <td>-2.378157</td>\n",
       "      <td>-6.168574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>rock.00099.wav</td>\n",
       "      <td>rock</td>\n",
       "      <td>1609.795082</td>\n",
       "      <td>422203.216152</td>\n",
       "      <td>1797.213044</td>\n",
       "      <td>120115.632927</td>\n",
       "      <td>0.362073</td>\n",
       "      <td>0.072915</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.105506</td>\n",
       "      <td>-1.916938</td>\n",
       "      <td>-2.414288</td>\n",
       "      <td>-5.815474</td>\n",
       "      <td>-12.545700</td>\n",
       "      <td>-9.121735</td>\n",
       "      <td>5.651028</td>\n",
       "      <td>3.684716</td>\n",
       "      <td>3.157386</td>\n",
       "      <td>-8.809851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  label     fsc_mean        fsc_var     fsb_mean  \\\n",
       "0    blues.00000.wav  blues  1784.165850  129774.064525  2002.449060   \n",
       "1    blues.00001.wav  blues  1530.176679  375850.073649  2039.036516   \n",
       "2    blues.00002.wav  blues  1552.811865  156467.643368  1747.702312   \n",
       "3    blues.00003.wav  blues  1070.106615  184355.942417  1596.412872   \n",
       "4    blues.00004.wav  blues  1835.004266  343399.939274  1748.172116   \n",
       "..               ...    ...          ...            ...          ...   \n",
       "994   rock.00095.wav   rock  2008.149458  282174.689224  2106.541053   \n",
       "995   rock.00096.wav   rock  2006.843354  182114.709510  2068.942009   \n",
       "996   rock.00097.wav   rock  2077.526598  231657.968040  1927.293153   \n",
       "997   rock.00098.wav   rock  1398.699344  240318.731073  1818.450280   \n",
       "998   rock.00099.wav   rock  1609.795082  422203.216152  1797.213044   \n",
       "\n",
       "           fsb_var  chroma_mean  chroma_var  rms_mean   rms_var  ...  \\\n",
       "0     85882.761315     0.362313    0.106962  0.130228  0.002827  ...   \n",
       "1    213843.755497     0.460052    0.142584  0.095948  0.002373  ...   \n",
       "2     76254.192257     0.273189    0.044912  0.175570  0.002746  ...   \n",
       "3    166441.494769     0.341006    0.062565  0.141093  0.006346  ...   \n",
       "4     88445.209036     0.192628    0.038132  0.091529  0.002303  ...   \n",
       "..             ...          ...         ...       ...       ...  ...   \n",
       "994   88609.749506     0.181401    0.029210  0.079486  0.000345  ...   \n",
       "995   82426.016726     0.273710    0.036364  0.076458  0.000588  ...   \n",
       "996   74717.124394     0.385682    0.074642  0.081651  0.000322  ...   \n",
       "997  109090.207161     0.469807    0.122644  0.083860  0.001211  ...   \n",
       "998  120115.632927     0.362073    0.072915  0.054454  0.000336  ...   \n",
       "\n",
       "     mfcc_mean21  mfcc_mean22  mfcc_mean23  mfcc_mean24  mfcc_mean25  \\\n",
       "0      -3.534350    -1.141433    -4.283032    -4.226195     0.915617   \n",
       "1      -4.095796    -1.239113    -2.849731    -4.350280     3.272610   \n",
       "2      -4.050981    -0.572249    -2.018496    -5.387675    -5.137322   \n",
       "3      -1.497070    -0.052236    -1.860378    -4.708420    -3.922396   \n",
       "4      -5.864221    -0.721730     0.956659    -1.220395     4.582734   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "994    -3.957475    -4.317051    -6.250848     0.721220    -4.338227   \n",
       "995    -7.678435    -3.787277    -6.231989     1.612385    -1.756582   \n",
       "996    -6.942582    -2.529781    -2.786954    -0.166313    -5.404921   \n",
       "997    -2.717012    -6.297633    -6.245030    -3.727469    -1.884362   \n",
       "998    -5.105506    -1.916938    -2.414288    -5.815474   -12.545700   \n",
       "\n",
       "     mfcc_mean26  mfcc_mean27  mfcc_mean28  mfcc_mean29  mfcc_mean30  \n",
       "0       0.912687    -5.761347    -3.932743     1.510824     2.698882  \n",
       "1       1.219840    -0.011623    -0.068070     3.977461    -0.455880  \n",
       "2      -7.807413    -1.173293    -0.211240     1.391639    -3.002489  \n",
       "3      -6.646778    -2.896451    -3.225220    -0.269411    -3.817974  \n",
       "4       0.304413    -1.278633    -4.487785    -0.413578     0.281198  \n",
       "..           ...          ...          ...          ...          ...  \n",
       "994    -6.950669    -5.784535    -8.634680    -5.663607    -2.196216  \n",
       "995    -2.808209    -2.458402   -10.967601    -6.270818    -7.800555  \n",
       "996    -6.479573    -3.047574    -5.260037     0.551845    -3.021486  \n",
       "997    -5.773752    -2.096236    -2.320376    -2.378157    -6.168574  \n",
       "998    -9.121735     5.651028     3.684716     3.157386    -8.809851  \n",
       "\n",
       "[999 rows x 85 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_music=pd.read_excel('feature_extraction_30.xls')\n",
    "data_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the label and features into 2 dataframes\n",
    "X = data_music.iloc[:,2:]\n",
    "Y = data_music['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train and tesy\n",
    "train_set, test_set, train_labels, test_labels = train_test_split(X, Y,test_size=0.2, random_state=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise the data \n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_scaled = min_max_scaler.fit_transform(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5719303797468355"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "NB_scores = cross_val_score(nb,X_train_scaled,train_labels, cv=10)\n",
    "NB_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.6670727848101266 <- parameters {'penalty': 'l1', 'max_iter': 3000, 'loss': 'log', 'alpha': 1e-05}\n",
      "score = 0.6307753164556962 <- parameters {'penalty': 'elasticnet', 'max_iter': 3000, 'loss': 'log', 'alpha': 1e-05}\n",
      "score = 0.6669620253164557 <- parameters {'penalty': 'l1', 'max_iter': 4000, 'loss': 'log', 'alpha': 1e-05}\n",
      "score = 0.6432911392405063 <- parameters {'penalty': 'elasticnet', 'max_iter': 4000, 'loss': 'log', 'alpha': 1e-05}\n",
      "score = 0.6871202531645569 <- parameters {'penalty': 'l1', 'max_iter': 5000, 'loss': 'log', 'alpha': 1e-05}\n",
      "score = 0.636993670886076 <- parameters {'penalty': 'elasticnet', 'max_iter': 5000, 'loss': 'log', 'alpha': 1e-05}\n",
      "score = 0.6933069620253165 <- parameters {'penalty': 'l1', 'max_iter': 3000, 'loss': 'log', 'alpha': 0.0001}\n",
      "score = 0.6833386075949367 <- parameters {'penalty': 'elasticnet', 'max_iter': 3000, 'loss': 'log', 'alpha': 0.0001}\n",
      "score = 0.7058227848101266 <- parameters {'penalty': 'l1', 'max_iter': 4000, 'loss': 'log', 'alpha': 0.0001}\n",
      "score = 0.6770886075949367 <- parameters {'penalty': 'elasticnet', 'max_iter': 4000, 'loss': 'log', 'alpha': 0.0001}\n",
      "score = 0.7045886075949367 <- parameters {'penalty': 'l1', 'max_iter': 5000, 'loss': 'log', 'alpha': 0.0001}\n",
      "score = 0.6808227848101266 <- parameters {'penalty': 'elasticnet', 'max_iter': 5000, 'loss': 'log', 'alpha': 0.0001}\n",
      "score = 0.6858069620253164 <- parameters {'penalty': 'l1', 'max_iter': 3000, 'loss': 'log', 'alpha': 0.001}\n",
      "score = 0.6546044303797467 <- parameters {'penalty': 'elasticnet', 'max_iter': 3000, 'loss': 'log', 'alpha': 0.001}\n",
      "score = 0.6732911392405063 <- parameters {'penalty': 'l1', 'max_iter': 4000, 'loss': 'log', 'alpha': 0.001}\n",
      "score = 0.6695727848101265 <- parameters {'penalty': 'elasticnet', 'max_iter': 4000, 'loss': 'log', 'alpha': 0.001}\n",
      "score = 0.6883227848101265 <- parameters {'penalty': 'l1', 'max_iter': 5000, 'loss': 'log', 'alpha': 0.001}\n",
      "score = 0.6721044303797468 <- parameters {'penalty': 'elasticnet', 'max_iter': 5000, 'loss': 'log', 'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "sgd = SGDClassifier()\n",
    "\n",
    "param_dist = {\n",
    "    'alpha': [1e-5,1e-4, 1e-3], # learning rate\n",
    "    'max_iter': [3000,4000,5000], # number of epochs\n",
    "    'loss': ['log'],\n",
    "    'penalty': ['l1', 'elasticnet']\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(sgd, param_distributions=param_dist,\n",
    "                                n_iter=18, cv=10,n_jobs = -1)\n",
    "rnd_search.fit(X_train_scaled,train_labels)\n",
    "\n",
    "rand_cv_res = rnd_search.cv_results_\n",
    "for mean_score, params in zip(rand_cv_res[\"mean_test_score\"], rand_cv_res[\"params\"]):\n",
    "    print(f\"score = {mean_score} <- parameters {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='log', max_iter=4000, penalty='l1')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.6433544303797468 <- parameters {'p': 1, 'n_neighbors': 19, 'leaf_size': 15}\n",
      "score = 0.6470727848101265 <- parameters {'p': 1, 'n_neighbors': 14, 'leaf_size': 22}\n",
      "score = 0.6170886075949367 <- parameters {'p': 2, 'n_neighbors': 26, 'leaf_size': 21}\n",
      "score = 0.6170886075949367 <- parameters {'p': 2, 'n_neighbors': 26, 'leaf_size': 18}\n",
      "score = 0.640759493670886 <- parameters {'p': 2, 'n_neighbors': 18, 'leaf_size': 6}\n",
      "score = 0.639509493670886 <- parameters {'p': 2, 'n_neighbors': 19, 'leaf_size': 25}\n",
      "score = 0.660870253164557 <- parameters {'p': 2, 'n_neighbors': 8, 'leaf_size': 23}\n",
      "score = 0.6583227848101266 <- parameters {'p': 2, 'n_neighbors': 6, 'leaf_size': 3}\n",
      "score = 0.6269936708860759 <- parameters {'p': 2, 'n_neighbors': 2, 'leaf_size': 24}\n",
      "score = 0.6558227848101266 <- parameters {'p': 2, 'n_neighbors': 15, 'leaf_size': 28}\n",
      "score = 0.6295411392405063 <- parameters {'p': 2, 'n_neighbors': 22, 'leaf_size': 15}\n",
      "score = 0.6208069620253165 <- parameters {'p': 1, 'n_neighbors': 26, 'leaf_size': 17}\n",
      "score = 0.632120253164557 <- parameters {'p': 1, 'n_neighbors': 21, 'leaf_size': 8}\n",
      "score = 0.6095727848101266 <- parameters {'p': 2, 'n_neighbors': 28, 'leaf_size': 8}\n",
      "score = 0.657120253164557 <- parameters {'p': 1, 'n_neighbors': 16, 'leaf_size': 7}\n",
      "score = 0.6633544303797468 <- parameters {'p': 2, 'n_neighbors': 12, 'leaf_size': 13}\n",
      "score = 0.6295411392405063 <- parameters {'p': 2, 'n_neighbors': 22, 'leaf_size': 8}\n",
      "score = 0.6571044303797469 <- parameters {'p': 2, 'n_neighbors': 9, 'leaf_size': 9}\n",
      "score = 0.6583386075949367 <- parameters {'p': 2, 'n_neighbors': 5, 'leaf_size': 21}\n",
      "score = 0.6195569620253164 <- parameters {'p': 2, 'n_neighbors': 24, 'leaf_size': 3}\n",
      "score = 0.614493670886076 <- parameters {'p': 1, 'n_neighbors': 29, 'leaf_size': 16}\n",
      "score = 0.6233069620253164 <- parameters {'p': 2, 'n_neighbors': 23, 'leaf_size': 5}\n",
      "score = 0.6483227848101265 <- parameters {'p': 2, 'n_neighbors': 13, 'leaf_size': 15}\n",
      "score = 0.6433069620253165 <- parameters {'p': 2, 'n_neighbors': 20, 'leaf_size': 9}\n",
      "score = 0.6670094936708859 <- parameters {'p': 1, 'n_neighbors': 1, 'leaf_size': 18}\n",
      "score = 0.6207753164556962 <- parameters {'p': 1, 'n_neighbors': 27, 'leaf_size': 9}\n",
      "score = 0.6308386075949367 <- parameters {'p': 1, 'n_neighbors': 24, 'leaf_size': 27}\n",
      "score = 0.6095727848101266 <- parameters {'p': 2, 'n_neighbors': 28, 'leaf_size': 2}\n",
      "score = 0.6583069620253165 <- parameters {'p': 2, 'n_neighbors': 3, 'leaf_size': 11}\n",
      "score = 0.6546044303797469 <- parameters {'p': 1, 'n_neighbors': 12, 'leaf_size': 13}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_dist = {'n_neighbors': list(range(1,30)),\n",
    "              'leaf_size' : list(range(1,30)),\n",
    "              'p': [1,2]\n",
    "            }\n",
    "\n",
    "rnd_search = RandomizedSearchCV(knn, param_distributions=param_dist,\n",
    "                                n_iter=30, cv=10,n_jobs = -1)\n",
    "rnd_search.fit(X_train_scaled,train_labels)\n",
    "\n",
    "rand_cv_res = rnd_search.cv_results_\n",
    "for mean_score, params in zip(rand_cv_res[\"mean_test_score\"], rand_cv_res[\"params\"]):\n",
    "    print(f\"score = {mean_score} <- parameters {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(leaf_size=18, n_neighbors=1, p=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.591996855345912 <- parameters {'kernel': 'linear', 'degree': 2, 'decision_function_shape': 'ovo', 'C': 0.1}\n",
      "score = 0.7445990566037736 <- parameters {'kernel': 'rbf', 'degree': 0, 'decision_function_shape': 'ovo', 'C': 100}\n",
      "score = 0.698309748427673 <- parameters {'kernel': 'linear', 'degree': 6, 'decision_function_shape': 'ovo', 'C': 10}\n",
      "score = 0.7445990566037736 <- parameters {'kernel': 'rbf', 'degree': 3, 'decision_function_shape': 'ovo', 'C': 100}\n",
      "score = 0.40047169811320754 <- parameters {'kernel': 'rbf', 'degree': 3, 'decision_function_shape': 'ovo', 'C': 0.1}\n",
      "score = 0.7096069182389937 <- parameters {'kernel': 'linear', 'degree': 4, 'decision_function_shape': 'ovo', 'C': 1}\n",
      "score = 0.7571147798742138 <- parameters {'kernel': 'rbf', 'degree': 2, 'decision_function_shape': 'ovo', 'C': 10}\n",
      "score = 0.6958883647798743 <- parameters {'kernel': 'rbf', 'degree': 0, 'decision_function_shape': 'ovo', 'C': 1}\n",
      "score = 0.7096069182389937 <- parameters {'kernel': 'linear', 'degree': 0, 'decision_function_shape': 'ovo', 'C': 1}\n",
      "score = 0.7445990566037736 <- parameters {'kernel': 'rbf', 'degree': 2, 'decision_function_shape': 'ovo', 'C': 100}\n",
      "score = 0.7445990566037736 <- parameters {'kernel': 'rbf', 'degree': 4, 'decision_function_shape': 'ovo', 'C': 100}\n",
      "score = 0.591996855345912 <- parameters {'kernel': 'linear', 'degree': 1, 'decision_function_shape': 'ovo', 'C': 0.1}\n",
      "score = 0.40047169811320754 <- parameters {'kernel': 'rbf', 'degree': 5, 'decision_function_shape': 'ovo', 'C': 0.1}\n",
      "score = 0.6782704402515722 <- parameters {'kernel': 'linear', 'degree': 5, 'decision_function_shape': 'ovo', 'C': 100}\n",
      "score = 0.6782704402515722 <- parameters {'kernel': 'linear', 'degree': 6, 'decision_function_shape': 'ovo', 'C': 100}\n",
      "score = 0.6782704402515722 <- parameters {'kernel': 'linear', 'degree': 4, 'decision_function_shape': 'ovo', 'C': 1000}\n",
      "score = 0.40047169811320754 <- parameters {'kernel': 'rbf', 'degree': 1, 'decision_function_shape': 'ovo', 'C': 0.1}\n",
      "score = 0.591996855345912 <- parameters {'kernel': 'linear', 'degree': 5, 'decision_function_shape': 'ovo', 'C': 0.1}\n",
      "score = 0.7445990566037736 <- parameters {'kernel': 'rbf', 'degree': 5, 'decision_function_shape': 'ovo', 'C': 1000}\n",
      "score = 0.7096069182389937 <- parameters {'kernel': 'linear', 'degree': 6, 'decision_function_shape': 'ovo', 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "\n",
    "param_dist = {'kernel' : ['linear', 'rbf'],\n",
    "              'C' : [0.1, 1, 10, 100, 1000],\n",
    "              'degree' : [0, 1, 2, 3, 4, 5, 6],\n",
    "              'decision_function_shape' :[\"ovo\"]\n",
    "                }\n",
    "\n",
    "rnd_search = RandomizedSearchCV(svm, param_distributions=param_dist,\n",
    "                                n_iter=20, cv=5,n_jobs = -1)\n",
    "rnd_search.fit(X_train_scaled,train_labels)\n",
    "\n",
    "rand_cv_res = rnd_search.cv_results_\n",
    "for mean_score, params in zip(rand_cv_res[\"mean_test_score\"], rand_cv_res[\"params\"]):\n",
    "    print(f\"score = {mean_score} <- parameters {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, decision_function_shape='ovo', degree=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.7058018867924527 <- parameters {'solver': 'lbfgs', 'penalty': 'l2', 'C': 100}\n",
      "score = 0.7033411949685535 <- parameters {'solver': 'liblinear', 'penalty': 'l2', 'C': 100}\n",
      "score = 0.720817610062893 <- parameters {'solver': 'sag', 'penalty': 'l2', 'C': 100}\n",
      "score = 0.7208176100628931 <- parameters {'solver': 'saga', 'penalty': 'l2', 'C': 100}\n",
      "score = 0.7145754716981132 <- parameters {'solver': 'lbfgs', 'penalty': 'l2', 'C': 10}\n",
      "score = 0.7070754716981132 <- parameters {'solver': 'liblinear', 'penalty': 'l2', 'C': 10}\n",
      "score = 0.715817610062893 <- parameters {'solver': 'sag', 'penalty': 'l2', 'C': 10}\n",
      "score = 0.7183254716981132 <- parameters {'solver': 'saga', 'penalty': 'l2', 'C': 10}\n",
      "score = 0.6921305031446541 <- parameters {'solver': 'lbfgs', 'penalty': 'l2', 'C': 1.0}\n",
      "score = 0.6783569182389937 <- parameters {'solver': 'liblinear', 'penalty': 'l2', 'C': 1.0}\n",
      "score = 0.6908805031446541 <- parameters {'solver': 'sag', 'penalty': 'l2', 'C': 1.0}\n",
      "score = 0.688372641509434 <- parameters {'solver': 'saga', 'penalty': 'l2', 'C': 1.0}\n",
      "score = 0.5519575471698113 <- parameters {'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.1}\n",
      "score = 0.5319418238993711 <- parameters {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.1}\n",
      "score = 0.5519575471698113 <- parameters {'solver': 'sag', 'penalty': 'l2', 'C': 0.1}\n",
      "score = 0.5519575471698113 <- parameters {'solver': 'saga', 'penalty': 'l2', 'C': 0.1}\n",
      "score = 0.4355503144654088 <- parameters {'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.01}\n",
      "score = 0.3929795597484277 <- parameters {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.01}\n",
      "score = 0.4355503144654088 <- parameters {'solver': 'sag', 'penalty': 'l2', 'C': 0.01}\n",
      "score = 0.4355503144654088 <- parameters {'solver': 'saga', 'penalty': 'l2', 'C': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\design-cj\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lg = LogisticRegression()\n",
    "\n",
    "param_dist = {'solver' : ['lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "              'penalty' : ['l2'],\n",
    "              'C' : [100, 10, 1.0, 0.1, 0.01]\n",
    "                }\n",
    "\n",
    "rnd_search = RandomizedSearchCV(lg, param_distributions=param_dist,\n",
    "                                n_iter=20, cv=5,n_jobs = -1)\n",
    "rnd_search.fit(X_train_scaled,train_labels)\n",
    "\n",
    "rand_cv_res = rnd_search.cv_results_\n",
    "for mean_score, params in zip(rand_cv_res[\"mean_test_score\"], rand_cv_res[\"params\"]):\n",
    "    print(f\"score = {mean_score} <- parameters {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, solver='saga')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "\n",
    "param_dist= {'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "            'max_features': ['auto', 'sqrt'],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "           }\n",
    "\n",
    "\n",
    "rnd_search = RandomizedSearchCV(rf, param_distributions=param_dist,\n",
    "                                n_iter=10, cv=5,n_jobs = -1)\n",
    "rnd_search.fit(X_train_scaled,train_labels)\n",
    "\n",
    "rand_cv_res = rnd_search.cv_results_\n",
    "for mean_score, params in zip(rand_cv_res[\"mean_test_score\"], rand_cv_res[\"params\"]):\n",
    "    print(f\"score = {mean_score} <- parameters {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPP = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),('LR',LogisticRegression(C=10, solver='saga')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Train  LR : 0.8886107634543179\n",
      "Accuracy LR : 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\design-cj\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "MPP.fit(train_set , train_labels)\n",
    "preds_train= MPP.predict(train_set)\n",
    "print('Accuracy on Train ', \"LR\", ':', accuracy_score(train_labels, preds_train))\n",
    "preds = MPP.predict(test_set)\n",
    "print('Accuracy', \"LR\", ':', accuracy_score(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
